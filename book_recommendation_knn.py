# -*- coding: utf-8 -*-
"""Copy of fcc_book_recommendation_knn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Q6-6fwsd1p6rEhqH6bZNnDK3K36aDBG8
"""

# import libraries (you may add additional imports but you may not have to)
import numpy as np
import pandas as pd
from scipy.sparse import csr_matrix
from sklearn.neighbors import NearestNeighbors
from sklearn.model_selection import GridSearchCV
import matplotlib.pyplot as plt

# get data files
!wget https://cdn.freecodecamp.org/project-data/books/book-crossings.zip

!unzip book-crossings.zip

books_filename = 'BX-Books.csv'
ratings_filename = 'BX-Book-Ratings.csv'

# import csv data into dataframes
df_books = pd.read_csv(
    books_filename,
    encoding = "ISO-8859-1",
    sep=";",
    header=0,
    names=['isbn', 'title', 'author'],
    usecols=['isbn', 'title', 'author'],
    dtype={'isbn': 'str', 'title': 'str', 'author': 'str'})

df_ratings = pd.read_csv(
    ratings_filename,
    encoding = "ISO-8859-1",
    sep=";",
    header=0,
    names=['user', 'isbn', 'rating'],
    usecols=['user', 'isbn', 'rating'],
    dtype={'user': 'int32', 'isbn': 'str', 'rating': 'float32'})

# add your code here - consider creating a new cell for each section of code
df_books.head(10)

df_ratings.head()

df_ratings.shape, df_ratings['user'].shape #all users will be unique

df_ratings.isnull().sum() # this shows if there are any null values

df_books.isnull().sum()

df_books_cleaned = df_books.loc[~df_books.author.isnull()] # here it''ll get the author's column and loc any value that is null
df_books_cleaned.isnull().sum()

df_ratings.shape, df_books_cleaned.shape

active_users = df_ratings.user.value_counts()[df_ratings.user.value_counts()>=200].index
popular_books = df_ratings.isbn.value_counts()[df_ratings.isbn.value_counts()>=100].index

df_ratings_cleaned = df_ratings.loc[(df_ratings.user.isin(active_users))]
df_books_cleaned = df_books_cleaned.loc[(df_books_cleaned.isbn.isin(popular_books))]

df_merged = pd.merge(left=df_ratings_cleaned, right= df_books_cleaned, on= 'isbn', how= 'inner')
print(df_merged.shape)
df_merged.head()

df_merged.isnull().sum()

df_unique = df_merged.drop_duplicates(['title', 'user'])
df_unique.head(10)

df_unique.shape

# df_unique.title.unique()

pivot = df_unique.pivot(index= 'title', columns= 'user', values= 'rating').fillna(0)
pivot = pivot.sort_index()
pivot

input = pivot.values
model = NearestNeighbors(metric = 'cosine', algorithm = 'brute')
model.fit(input)

# input
book = 'The Lovely Bones: A Novel'
pivot.loc[book, :].sum()

# function to return recommended books - this will be tested
def get_recommends(book = "Where the Heart Is (Oprah's Book Club (Paperback))"):
  dist, suggested_books = model.kneighbors(pivot.loc[book].values.reshape(1,-1), n_neighbors=6)
  # return suggested_books[0]
  books = pivot.iloc[suggested_books[0]].index.values
  result = list(zip(books, dist[0]))
  result[0] = result[0][0]
  result[1] = sorted([[book, distance] for book, distance in result[1:]], key=lambda x: -x[1])[:4]
  recommended_books = result[:2]
  return recommended_books

get_recommends()

books = get_recommends("Where the Heart Is (Oprah's Book Club (Paperback))")
print(books)

def test_book_recommendation():
  test_pass = True
  recommends = get_recommends("Where the Heart Is (Oprah's Book Club (Paperback))")
  if recommends[0] != "Where the Heart Is (Oprah's Book Club (Paperback))":
    test_pass = False
  recommended_books = ["I'll Be Seeing You", 'The Weight of Water', 'The Surgeon', 'I Know This Much Is True']
  recommended_books_dist = [0.8, 0.77, 0.77, 0.77]
  for i in range(2): 
    if recommends[1][i][0] not in recommended_books:
      test_pass = False
    if abs(recommends[1][i][1] - recommended_books_dist[i]) >= 0.05:
      test_pass = False
  if test_pass:
    print("You passed the challenge! ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰")
  else:
    print("You haven't passed yet. Keep trying!")

test_book_recommendation()